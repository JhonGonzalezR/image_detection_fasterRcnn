# -*- coding: utf-8 -*-
"""Image_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1guGaULZqO8eKPSCiZHFVItQu_ODJ8eE4

### Importar dataset
"""

!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="OPoOED9EcJjhWXYbd9Vv")
project = rf.workspace("universidad-autnoma-de-occidente").project("miniproyecto-redes")
dataset = project.version(11).download("tfrecord")

"""## Pipeline

[tensorflow-object-detection-api-tutorial](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/)

### Imports
"""

import os
import pandas as pd
import json
import shutil

"""[TensorFlow SLIM](https://github.com/google-research/tf-slim)"""

!pip install tf_slim

"""### Modify label map"""

labels = [{'name':'Cuchara', 'id':1},{'name':'Plato', 'id':2},{'name':'Pocillo', 'id':3},{'name':'Sarten', 'id':4},{'name':'Vaso', 'id':5}]
with open("label_map.pbtxt","w") as f:
  for label in labels:
    f.write('item { \n')
    f.write('\tname:\'{}\'\n'.format(label['name']))
    f.write('\tid:{}\n'.format(label['id']))
    f.write('}\n')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content
!git clone --quiet https://github.com/tensorflow/models.git
# %cd /content/models/
# %cd /content/models/research
!protoc object_detection/protos/*.proto --python_out=.
os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'

"""### Get model

[TensorFlow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)
"""

!wget --no-check-certificate http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.tar.gz \
-O /content/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.tar.gz

"""### Unzid model"""

!tar -zxvf /content/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.tar.gz
output_path = 'faster_rcnn_resnet101_v1_640x640_coco17_tpu-8'
output_path = os.path.join(os.getcwd(), output_path)
print("La carpeta se almacenó en {}".format(output_path))

path_training = '/content/faster_rcnn_resnet101'
os.mkdir(path_training)

"""### Copy config file"""

source_config = "{}/pipeline.config".format(output_path)
target_config = "{}/pipeline.config".format(path_training)
shutil.copyfile(source_config, target_config)#mueve el archivo de la carpeta A a la carpeta B

import tensorflow as tf
from object_detection.utils import config_util
from object_detection.protos import pipeline_pb2
from google.protobuf import text_format

config = config_util.get_configs_from_pipeline_file(target_config)

config

#Se hace para editar este archivo
pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()
with tf.io.gfile.GFile(target_config, "r") as f:
  proto_str = f.read()
  text_format.Merge(proto_str, pipeline_config)

pipeline_config

"""### TFRecord and label_map Path"""

label_map_pbtxt_fname = "/content/label_map.pbtxt"
train_record_fname = "/content/MiniProyecto-Redes-11/train/utencilios.tfrecord"
test_record_fname = "/content/MiniProyecto-Redes-11/test/utencilios.tfrecord"

"""### Modify config file"""

pipeline_config.model.faster_rcnn.num_classes = 5
pipeline_config.train_config.batch_size = 4
# pipeline_config.train_config.fine_tune_checkpoint = "{}/checkpoint/ckpt-0".format(output_path)
pipeline_config.train_config.fine_tune_checkpoint = "{}/checkpoint/ckpt-0".format(output_path)
pipeline_config.train_config.fine_tune_checkpoint_type = "detection"
pipeline_config.train_input_reader.label_map_path = label_map_pbtxt_fname
pipeline_config.train_input_reader.tf_record_input_reader.input_path[0] = train_record_fname
pipeline_config.eval_input_reader[0].label_map_path = label_map_pbtxt_fname
pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[0] = test_record_fname
pipeline_config.train_config.optimizer.momentum_optimizer.learning_rate.cosine_decay_learning_rate.learning_rate_base = 0.002
pipeline_config.train_config.optimizer.momentum_optimizer.learning_rate.cosine_decay_learning_rate.warmup_learning_rate = 0.001

pipeline_config

config_text = text_format.MessageToString(pipeline_config)
with tf.io.gfile.GFile(target_config, "wb") as f:
  f.write(config_text)

"""- LVIS API enables reading and interacting with annotation files, visualizing annotations, and evaluating results.
- The TensorFlow official models are a collection of models that use TensorFlow’s high-level APIs. They are intended to be well-maintained, tested, and kept up to date with the latest TensorFlow API. They should also be reasonably optimized for fast performance while still being easy to read.
"""

!pip install lvis
!pip install tf-models-official

!pip install tensorflow-io

# !pip install lvis
# !pip install tf-models-official2.7.0

!dir

"""### Train model"""

num_steps = 2000
model_dir = "/content/Model_saved"

!python /content/models/research/object_detection/model_main_tf2.py \
--pipeline_config_path={target_config} \
--model_dir={model_dir} \
--num_train_steps={num_steps}

"""## Results

### Tensorboard
"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir "/content/Model_saved"# "/content/ssd_mobilenet"

"""### Save model"""

output_directory = "/content/Model_saved/Model_2"
!python /content/models/research/object_detection/exporter_main_v2.py \
--input_type image_tensor \
--pipeline_config_path {target_config} \
--trained_checkpoint_dir {model_dir} \
--output_directory {output_directory}

!zip -r /content/Model_saved/Model_2/fine_tuned_model2.zip /content/Model_saved/Model_2

# Commented out IPython magic to ensure Python compatibility.
#downloading test images from Roboflow
#export dataset above with format COCO JSON
#or import your test images via other means.
# %mkdir /content/test/
# %cd /content/test/
!curl -L "https://app.roboflow.com/ds/V8wMkb2PrA?key=5x2SkvKhx6" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip

PATH_TO_SAVED_MODEL = "/content/Model_saved/Model_2/saved_model"

detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)

from object_detection.utils import label_map_util

category_index=label_map_util.create_category_index_from_labelmap('/content/label_map.pbtxt', use_display_name=True)

# Commented out IPython magic to ensure Python compatibility.
import numpy as np

from object_detection.utils import visualization_utils as viz_utils
from PIL import Image
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings
# %matplotlib inline


image_path = '/content/test/test/Utencilios137_jpg.rf.cde2d174786bf25938acadd5dff641f1.jpg'
IMAGE_PATHS = '/content/test/test'

def load_image_into_numpy_array(path):
    """Load an image from file into a numpy array.

    Puts image into numpy array to feed into tensorflow graph.
    Note that by convention we put it into a numpy array with shape
    (height, width, channels), where channels=3 for RGB.

    Args:
      path: the file path to the image

    Returns:
      uint8 numpy array with shape (img_height, img_width, 3)
    """
    return np.array(Image.open(path))

import os

IMAGE_DIR = '/content/test/test'
IMAGE_PATHS = [os.path.join(IMAGE_DIR, f) for f in os.listdir(IMAGE_DIR) if f.endswith('.jpg')]


for image_path in IMAGE_PATHS:

    print('Running inference for {}... '.format(image_path), end='')

    image_np = load_image_into_numpy_array(image_path)

    # Things to try:
    # Flip horizontally
    # image_np = np.fliplr(image_np).copy()

    # Convert image to grayscale
    # image_np = np.tile(
    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)

    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.
    input_tensor = tf.convert_to_tensor(image_np)
    # The model expects a batch of images, so add an axis with `tf.newaxis`.
    input_tensor = input_tensor[tf.newaxis, ...]

    # input_tensor = np.expand_dims(image_np, 0)
    detections = detect_fn(input_tensor)

    # All outputs are batches tensors.
    # Convert to numpy arrays, and take index [0] to remove the batch dimension.
    # We're only interested in the first num_detections.
    num_detections = int(detections.pop('num_detections'))
    detections = {key: value[0, :num_detections].numpy()
                   for key, value in detections.items()}
    detections['num_detections'] = num_detections

    # detection_classes should be ints.
    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)

    image_np_with_detections = image_np.copy()

    viz_utils.visualize_boxes_and_labels_on_image_array(
          image_np_with_detections,
          detections['detection_boxes'],
          detections['detection_classes'],
          detections['detection_scores'],
          category_index,
          use_normalized_coordinates=True,
          max_boxes_to_draw=200,
          min_score_thresh=.30,
          agnostic_mode=False)

    plt.figure(figsize=(24,32))
    plt.imshow(image_np_with_detections[0])
    plt.show()
    print('Done')
#plt.show()

#sphinx_gallery_thumbnail_numer = 2

plt.figure(figsize=(24,32))
plt.imshow(image_np_with_detections[0])
plt.show()